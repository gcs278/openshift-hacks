PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
TERM=xterm
HOSTNAME=e2e-gcp-upgrade-openshift-e2e-test
NSS_SDB_USE_CACHE=no
JOB_TYPE=periodic
OPENSHIFT_CI=true
PROW_JOB_ID=4.8.0-0.ci-2022-08-23-181404-upgrade-gcp-minor
ENTRYPOINT_OPTIONS={"timeout":14400000000000,"grace_period":600000000000,"artifact_dir":"/logs/artifacts","args":["/bin/bash","-c","#!/bin/bash\nset -eu\n#!/bin/bash\n\nset -o nounset\nset -o errexit\nset -o pipefail\n\nexport AWS_SHARED_CREDENTIALS_FILE=${CLUSTER_PROFILE_DIR}/.awscred\nexport AZURE_AUTH_LOCATION=${CLUSTER_PROFILE_DIR}/osServicePrincipal.json\nexport GCP_SHARED_CREDENTIALS_FILE=${CLUSTER_PROFILE_DIR}/gce.json\nexport ALIBABA_CLOUD_CREDENTIALS_FILE=${SHARED_DIR}/alibabacreds.ini\nexport HOME=/tmp/home\nexport PATH=/usr/libexec/origin:$PATH\n\n# HACK: HyperShift clusters use their own profile type, but the cluster type\n# underneath is actually AWS and the type identifier is derived from the profile\n# type. For now, just treat the `hypershift` type the same as `aws` until\n# there's a clean way to decouple the notion of a cluster provider and the\n# platform type.\n#\n# See also: https://issues.redhat.com/browse/DPTP-1988\nif [[ \"${CLUSTER_TYPE}\" == \"hypershift\" ]]; then\n    export CLUSTER_TYPE=\"aws\"\n    echo \"Overriding 'hypershift' cluster type to be 'aws'\"\nfi\n\n# For disconnected or otherwise unreachable environments, we want to\n# have steps use an HTTP(S) proxy to reach the API server. This proxy\n# configuration file should export HTTP_PROXY, HTTPS_PROXY, and NO_PROXY\n# environment variables, as well as their lowercase equivalents (note\n# that libcurl doesn't recognize the uppercase variables).\nif test -f \"${SHARED_DIR}/proxy-conf.sh\"\nthen\n    # shellcheck disable=SC1090\n    source \"${SHARED_DIR}/proxy-conf.sh\"\nfi\n\nif [[ -n \"${TEST_CSI_DRIVER_MANIFEST}\" ]]; then\n    export TEST_CSI_DRIVER_FILES=${SHARED_DIR}/${TEST_CSI_DRIVER_MANIFEST}\nfi\n\ntrap 'CHILDREN=$(jobs -p); if test -n \"${CHILDREN}\"; then kill ${CHILDREN} \u0026\u0026 wait; fi' TERM\n\nmkdir -p \"${HOME}\"\n\n# Override the upstream docker.io registry due to issues with rate limiting\n# https://bugzilla.redhat.com/show_bug.cgi?id=1895107\n# sjenning: TODO: use of personal repo is temporary; should find long term location for these mirrored images\nexport KUBE_TEST_REPO_LIST=${HOME}/repo_list.yaml\ncat \u003c\u003cEOF \u003e ${KUBE_TEST_REPO_LIST}\ndockerLibraryRegistry: quay.io/sjenning\ndockerGluster: quay.io/sjenning\nEOF\n\n# if the cluster profile included an insights secret, install it to the cluster to\n# report support data from the support-operator\nif [[ -f \"${CLUSTER_PROFILE_DIR}/insights-live.yaml\" ]]; then\n    oc create -f \"${CLUSTER_PROFILE_DIR}/insights-live.yaml\" || true\nfi\n\n# if this test requires an SSH bastion and one is not installed, configure it\nKUBE_SSH_BASTION=\"$( oc --insecure-skip-tls-verify get node -l node-role.kubernetes.io/master -o 'jsonpath={.items[0].status.addresses[?(@.type==\"ExternalIP\")].address}' ):22\"\nKUBE_SSH_KEY_PATH=${CLUSTER_PROFILE_DIR}/ssh-privatekey\nexport KUBE_SSH_BASTION KUBE_SSH_KEY_PATH\nif [[ -n \"${TEST_REQUIRES_SSH-}\" ]]; then\n    export SSH_BASTION_NAMESPACE=test-ssh-bastion\n    echo \"Setting up ssh bastion\"\n\n    # configure the local container environment to have the correct SSH configuration\n    mkdir -p ~/.ssh\n    cp \"${KUBE_SSH_KEY_PATH}\" ~/.ssh/id_rsa\n    chmod 0600 ~/.ssh/id_rsa\n    if ! whoami \u0026\u003e /dev/null; then\n        if [[ -w /etc/passwd ]]; then\n            echo \"${USER_NAME:-default}:x:$(id -u):0:${USER_NAME:-default} user:${HOME}:/sbin/nologin\" \u003e\u003e /etc/passwd\n        fi\n    fi\n\n    # if this is run from a flow that does not have the ssh-bastion step, deploy the bastion\n    if ! oc get -n \"${SSH_BASTION_NAMESPACE}\" ssh-bastion; then\n        curl https://raw.githubusercontent.com/eparis/ssh-bastion/master/deploy/deploy.sh | bash -x\n    fi\n\n    # locate the bastion host for use within the tests\n    for _ in $(seq 0 30); do\n        # AWS fills only .hostname of a service\n        BASTION_HOST=$(oc get service -n \"${SSH_BASTION_NAMESPACE}\" ssh-bastion -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')\n        if [[ -n \"${BASTION_HOST}\" ]]; then break; fi\n        # Azure fills only .ip of a service. Use it as bastion host.\n        BASTION_HOST=$(oc get service -n \"${SSH_BASTION_NAMESPACE}\" ssh-bastion -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n        if [[ -n \"${BASTION_HOST}\" ]]; then break; fi\n        echo \"Waiting for SSH bastion load balancer service\"\n        sleep 10\n    done\n    if [[ -z \"${BASTION_HOST}\" ]]; then\n        echo \u003e\u00262 \"Failed to find bastion address, exiting\"\n        exit 1\n    fi\n    export KUBE_SSH_BASTION=\"${BASTION_HOST}:22\"\nfi\n\n\n# set up cloud-provider-specific env vars\ncase \"${CLUSTER_TYPE}\" in\ngcp)\n    export GOOGLE_APPLICATION_CREDENTIALS=\"${GCP_SHARED_CREDENTIALS_FILE}\"\n    # In k8s 1.24 this is required to run GCP PD tests. See: https://github.com/kubernetes/kubernetes/pull/109541\n    export ENABLE_STORAGE_GCE_PD_DRIVER=\"yes\"\n    export KUBE_SSH_USER=core\n    mkdir -p ~/.ssh\n    cp \"${CLUSTER_PROFILE_DIR}/ssh-privatekey\" ~/.ssh/google_compute_engine || true\n    # TODO: make openshift-tests auto-discover this from cluster config\n    PROJECT=\"$(oc get -o jsonpath='{.status.platformStatus.gcp.projectID}' infrastructure cluster)\"\n    REGION=\"$(oc get -o jsonpath='{.status.platformStatus.gcp.region}' infrastructure cluster)\"\n    export TEST_PROVIDER=\"{\\\"type\\\":\\\"gce\\\",\\\"region\\\":\\\"${REGION}\\\",\\\"multizone\\\": true,\\\"multimaster\\\":true,\\\"projectid\\\":\\\"${PROJECT}\\\"}\"\n    ;;\naws|aws-arm64)\n    mkdir -p ~/.ssh\n    cp \"${CLUSTER_PROFILE_DIR}/ssh-privatekey\" ~/.ssh/kube_aws_rsa || true\n    export PROVIDER_ARGS=\"-provider=aws -gce-zone=us-east-1\"\n    # TODO: make openshift-tests auto-discover this from cluster config\n    REGION=\"$(oc get -o jsonpath='{.status.platformStatus.aws.region}' infrastructure cluster)\"\n    ZONE=\"$(oc get -o jsonpath='{.items[0].metadata.labels.failure-domain\\.beta\\.kubernetes\\.io/zone}' nodes)\"\n    export TEST_PROVIDER=\"{\\\"type\\\":\\\"aws\\\",\\\"region\\\":\\\"${REGION}\\\",\\\"zone\\\":\\\"${ZONE}\\\",\\\"multizone\\\":true,\\\"multimaster\\\":true}\"\n    export KUBE_SSH_USER=core\n    ;;\nazure4) export TEST_PROVIDER=azure;;\nazurestack)\n    export TEST_PROVIDER=\"none\"\n    export AZURE_AUTH_LOCATION=${SHARED_DIR}/osServicePrincipal.json\n    ;;\nvsphere)\n    # shellcheck disable=SC1090\n    source \"${SHARED_DIR}/govc.sh\"\n    export VSPHERE_CONF_FILE=\"${SHARED_DIR}/vsphere.conf\"\n    oc -n openshift-config get cm/cloud-provider-config -o jsonpath='{.data.config}' \u003e \"$VSPHERE_CONF_FILE\"\n    # The test suite requires a vSphere config file with explicit user and password fields.\n    sed -i \"/secret-name \\=/c user = \\\"${GOVC_USERNAME}\\\"\" \"$VSPHERE_CONF_FILE\"\n    sed -i \"/secret-namespace \\=/c password = \\\"${GOVC_PASSWORD}\\\"\" \"$VSPHERE_CONF_FILE\"\n    export TEST_PROVIDER=vsphere;;\nalibabacloud)\n    mkdir -p ~/.ssh\n    cp \"${CLUSTER_PROFILE_DIR}/ssh-privatekey\" ~/.ssh/kube_alibaba_rsa || true\n    export PROVIDER_ARGS=\"-provider=alibabacloud -gce-zone=us-east-1\"\n    # TODO: make openshift-tests auto-discover this from cluster config\n    REGION=\"$(oc get -o jsonpath='{.status.platformStatus.alibabacloud.region}' infrastructure cluster)\"\n    export TEST_PROVIDER=\"{\\\"type\\\":\\\"alibabacloud\\\",\\\"region\\\":\\\"${REGION}\\\",\\\"multizone\\\":true,\\\"multimaster\\\":true}\"\n    export KUBE_SSH_USER=core\n;;\nopenstack*)\n    # shellcheck disable=SC1090\n    source \"${SHARED_DIR}/cinder_credentials.sh\"\n    if test -n \"${HTTP_PROXY:-}\" -o -n \"${HTTPS_PROXY:-}\"; then\n        export TEST_PROVIDER='{\"type\":\"openstack\",\"disconnected\":true}'\n    else\n        export TEST_PROVIDER='{\"type\":\"openstack\"}'\n    fi\n    ;;\novirt) export TEST_PROVIDER='{\"type\":\"ovirt\"}';;\nibmcloud)\n    export TEST_PROVIDER='{\"type\":\"ibmcloud\"}'\n    IC_API_KEY=\"$(\u003c \"${CLUSTER_PROFILE_DIR}/ibmcloud-api-key\")\"\n    export IC_API_KEY\n    ;;\nnutanix) export TEST_PROVIDER='{\"type\":\"nutanix\"}' ;;\n*) echo \u003e\u00262 \"Unsupported cluster type '${CLUSTER_TYPE}'\"; exit 1;;\nesac\n\nmkdir -p /tmp/output\ncd /tmp/output\n\nif [[ \"${CLUSTER_TYPE}\" == gcp ]]; then\n    pushd /tmp\n    curl -O https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-256.0.0-linux-x86_64.tar.gz\n    tar -xzf google-cloud-sdk-256.0.0-linux-x86_64.tar.gz\n    export PATH=$PATH:/tmp/google-cloud-sdk/bin\n    mkdir gcloudconfig\n    export CLOUDSDK_CONFIG=/tmp/gcloudconfig\n    gcloud auth activate-service-account --key-file=\"${GCP_SHARED_CREDENTIALS_FILE}\"\n    gcloud config set project \"${PROJECT}\"\n    popd\nfi\n\n# Preserve the \u0026\u0026 chaining in this function, because it is called from and AND-OR list so it doesn't get errexit.\nfunction upgrade() {\n    set -x \u0026\u0026\n    TARGET_RELEASES=\"${OPENSHIFT_UPGRADE_RELEASE_IMAGE_OVERRIDE:-}\" \u0026\u0026\n    if [[ -f \"${SHARED_DIR}/override-upgrade\" ]]; then\n        TARGET_RELEASES=\"$(\u003c \"${SHARED_DIR}/override-upgrade\")\" \u0026\u0026\n        echo \"Overriding upgrade target to ${TARGET_RELEASES}\"\n    fi \u0026\u0026\n    openshift-tests run-upgrade \"${TEST_UPGRADE_SUITE}\" \\\n        --to-image \"${TARGET_RELEASES}\" \\\n        --options \"${TEST_UPGRADE_OPTIONS-}\" \\\n        --provider \"${TEST_PROVIDER}\" \\\n        -o \"${ARTIFACT_DIR}/e2e.log\" \\\n        --junit-dir \"${ARTIFACT_DIR}/junit\" \u0026\n    wait \"$!\" \u0026\u0026\n    set +x\n}\n\n# upgrade_conformance runs the upgrade and the parallel tests, and exits with an error if either fails.\nfunction upgrade_conformance() {\n    local exit_code=0 \u0026\u0026\n    upgrade || exit_code=$? \u0026\u0026\n    PROGRESSING=\"$(oc get -o jsonpath='{.status.conditions[?(@.type == \"Progressing\")].status}' clusterversion version)\" \u0026\u0026\n    if test False = \"${PROGRESSING}\"\n    then\n        TEST_LIMIT_START_TIME=\"$(date +%s)\" TEST_SUITE=openshift/conformance/parallel suite || exit_code=$?\n    else\n        echo \"Skipping conformance suite because post-update ClusterVersion Progressing=${PROGRESSING}\"\n    fi \u0026\u0026\n    return $exit_code\n}\n\nfunction upgrade_paused() {\n    set -x\n    unset TEST_SUITE\n    TARGET_RELEASES=\"${OPENSHIFT_UPGRADE_RELEASE_IMAGE_OVERRIDE:-}\"\n    if [[ -f \"${SHARED_DIR}/override-upgrade\" ]]; then\n        TARGET_RELEASES=\"$(\u003c \"${SHARED_DIR}/override-upgrade\")\"\n        echo \"Overriding upgrade target to ${TARGET_RELEASES}\"\n    fi\n    # Split TARGET_RELEASES by commas, producing two releases\n    OPENSHIFT_UPGRADE0_RELEASE_IMAGE_OVERRIDE=\"$(echo $TARGET_RELEASES | cut -f1 -d,)\"\n    OPENSHIFT_UPGRADE1_RELEASE_IMAGE_OVERRIDE=\"$(echo $TARGET_RELEASES | cut -f2 -d,)\"\n\n    oc patch mcp/worker --type merge --patch '{\"spec\":{\"paused\":true}}'\n\n    echo \"Starting control-plane upgrade to ${OPENSHIFT_UPGRADE0_RELEASE_IMAGE_OVERRIDE}\"\n    openshift-tests run-upgrade \"${TEST_UPGRADE_SUITE}\" \\\n        --to-image \"${OPENSHIFT_UPGRADE0_RELEASE_IMAGE_OVERRIDE}\" \\\n        --options \"${TEST_UPGRADE_OPTIONS-}\" \\\n        --provider \"${TEST_PROVIDER}\" \\\n        -o \"${ARTIFACT_DIR}/e2e.log\" \\\n        --junit-dir \"${ARTIFACT_DIR}/junit\" \u0026\n    wait \"$!\"\n    echo \"Upgraded control-plane to ${OPENSHIFT_UPGRADE0_RELEASE_IMAGE_OVERRIDE}\"\n\n    echo \"Starting control-plane upgrade to ${OPENSHIFT_UPGRADE1_RELEASE_IMAGE_OVERRIDE}\"\n    openshift-tests run-upgrade \"${TEST_UPGRADE_SUITE}\" \\\n        --to-image \"${OPENSHIFT_UPGRADE1_RELEASE_IMAGE_OVERRIDE}\" \\\n        --options \"${TEST_UPGRADE_OPTIONS-}\" \\\n        --provider \"${TEST_PROVIDER}\" \\\n        -o \"${ARTIFACT_DIR}/e2e.log\" \\\n        --junit-dir \"${ARTIFACT_DIR}/junit\" \u0026\n    wait \"$!\"\n    echo \"Upgraded control-plane to ${OPENSHIFT_UPGRADE1_RELEASE_IMAGE_OVERRIDE}\"\n\n    echo \"Starting worker upgrade to ${OPENSHIFT_UPGR